# ConUHacksXMotionDetector

ğŸ¨ AirMotion Canvas

Draw in the air using hand gestures and real-time computer vision

ğŸ§© Problem Statement

Traditional drawing tools require physical contact devices. These tools may not always be accessible, intuitive, or hygienic.

There is a need for a natural, contactless drawing interface that allows users to interact with a digital canvas using simple hand gestures and real-time motion sensing.

ğŸ’¡ Solution Overview

AirMotion Canvas is a gesture-controlled virtual drawing system that allows users to draw in mid-air using their index finger. The system uses computer vision and hand-tracking to detect gestures and translate them into drawing actions on a digital canvas.

Additionally, a motion detection module monitors environmental movement, enabling future extensions such as gesture-based mode switching, activity detection, or smart interaction triggers.

âœ¨ Key Features

Real-time hand tracking using MediaPipe

Gesture-based drawing and pause control

Smooth stroke rendering with dynamic tracking

Motion detection using background subtraction

Modular engine-based architecture

Live visual feedback for gestures and motion

ğŸ—ï¸ System Architecture

The system is divided into two independent processing engines:

Air Canvas Engine

Detects hand landmarks

Identifies gestures (Draw / Hover)

Renders strokes onto a virtual canvas

Motion Detector Engine

Tracks  motion

Detects movement regions using frame differencing

Outputs motion events for future integration


âš™ï¸ Installation & Setup
Prerequisites

Python 3.8+

Webcam

Supported OS: Windows / macOS / Linux


Note: A main controller file can be added to combine both engines into a unified pipeline.

ğŸ”„ How It Works (Step-by-Step)

Capture live video frames from the camera

Flip and preprocess frames for natural interaction

Detect hand landmarks using MediaPipe

Identify finger states (index up, middle up/down)

Map gestures:

Index up â†’ Draw

Index + Middle up â†’ Hover (pause)

Draw strokes onto a transparent canvas layer

Detect motion using background subtraction

Merge canvas and camera feed into final output

ğŸ§ª Example Use Cases

Touchless drawing or whiteboard systems

Interactive presentations or classrooms

Computer vision learning projects

ğŸ“ Folder Structure
project-root/
â”‚
â”œâ”€â”€ air_canvas.py          # Hand tracking and drawing engine
â”œâ”€â”€ motion_detector.py     # Motion detection engine
â”œâ”€â”€ main.py                # (Placeholder) Application entry point
â”œâ”€â”€ requirements.txt       # Dependencies
â””â”€â”€ README.md

ğŸ§  Challenges & Learnings

Stabilizing hand tracking during fast movement

Reducing false positives in motion detection

Managing drawing continuity between frames

Designing gesture logic that feels natural and intuitive

Building modular, reusable computer vision components

ğŸ Conclusion

AirMotion Canvas demonstrates how computer vision can enable natural human-computer interaction without physical contact. By combining hand tracking and motion detection in a modular design, the project lays a strong foundation for future smart interaction systems and real-world applications.
Clean, modern design using:

Cards

Icons

Status colors (green = active, red = alert)

Designed specifically to look advanced and professional for judges

All styling organized and reusable via CSS style


8ï¸âƒ£ Files Delivered

index.html â†’ Dashboard layout and structure 

index

style.css â†’ Complete UI styling and animations 

style

app.js â†’ All dashboard logic, simulation, and interactions 

app
